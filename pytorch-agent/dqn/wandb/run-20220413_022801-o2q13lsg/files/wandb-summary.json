{"episode": 178, "mean episodic reward": 1.2625698324022345, "_timestamp": 1649831988, "_runtime": 707, "reward per episode": 3.0, "step_count": 251, "loss per episode": 633.1093139648438, "mean episodic loss": 46093.19140625, "epsilon": 0.8389, "_step": 178}
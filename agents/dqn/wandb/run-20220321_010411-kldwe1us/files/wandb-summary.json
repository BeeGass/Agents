{"episode": 17, "mean_reward": 0.1111111111111111, "_timestamp": 1647839488, "_runtime": 437, "reward": 2.0, "epsilon": 0.6581005077103117, "_step": 17, "_wandb": {"runtime": 450}}